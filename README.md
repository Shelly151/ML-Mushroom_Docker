# **ğŸš€ ML Model Deployment Using Docker ğŸ§ ğŸ³**  

This project demonstrates how to **build and deploy** a Machine Learning (ML) model using **Docker**.  
The model is trained on the **mushrooms dataset**, and we use **Streamlit** to create an interactive web UI for predictions.  

---

## **ğŸ“š Prerequisites**  

Before you begin, make sure you have the following installed:  

âœ… **Docker** ğŸ³  
âœ… **Python (3.9+)** ğŸ–  
âœ… **ML Dependencies** (listed in `requirements.txt`)  

---

## **ğŸ“Œ Installation & Setup**  

### **1ï¸âƒ£ Verify Docker & Python Installation**  

Check if **Docker** and **Python** are installed by running:  

```bash
docker --version  
python --version  
```

---

### **2ï¸âƒ£ Clone the Repository & Prepare Files**  

Clone the **GitHub repository** containing the ML model (`app.py`) and dataset (`mushrooms.csv`):  

```bash
git clone https://github.com/yourusername/ml-docker-project.git  
cd ml-docker-project  
```

Create a `requirements.txt` file to manage dependencies:  

```bash
pip freeze > requirements.txt  
```

---

### **3ï¸âƒ£ Create the Dockerfile**  

A **Dockerfile** defines the environment for running the ML model. Hereâ€™s an optimized version:  

```dockerfile
# Use a lightweight Python image  
FROM python:3.9-slim  

# Set the working directory  
WORKDIR /app  

# Copy necessary files  
COPY app.py /app  
COPY requirements.txt /app  
COPY mushrooms.csv /app  

# Upgrade pip and install dependencies  
RUN python -m pip install --upgrade pip  
RUN pip install -r requirements.txt  

# Expose the port for Streamlit  
EXPOSE 8501  

# Run the application using Streamlit  
ENTRYPOINT ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]  
```

---

### **4ï¸âƒ£ Build the Docker Image**  

Run the following command to build the Docker image:  

```bash
docker build -t ml-model .
```

Verify the image creation:  

```bash
docker images  
```

---

### **5ï¸âƒ£ Run the ML Model in a Docker Container**  

Start the container and expose it on port **8501**:  

```bash
docker run -p 8501:8501 ml-model  
```

---

### **6ï¸âƒ£ Access the Web Interface**  

Once the container is running, open your browser and go to:  

ğŸ”— **http://localhost:8501**  

You should now see the ML modelâ€™s **interactive UI** built with **Streamlit**! ğŸ‰  

---

## **ğŸš€ Pushing the Container to Docker Hub**  

### **1ï¸âƒ£ Log in to Docker Hub**  

```bash
docker login  
```

### **2ï¸âƒ£ Tag the Docker Image**  

Replace `yourdockerhubusername` with your **actual** Docker Hub username:  

```bash
docker tag ml-model yourdockerhubusername/ml-model  
```

### **3ï¸âƒ£ Push the Image to Docker Hub**  

```bash
docker push yourdockerhubusername/ml-model  
```

---

## **ğŸ† Conclusion**  

ğŸ’  You have successfully **containerized** and **deployed** an ML model using **Docker**!  
This setup ensures **scalability**, **portability**, and **easy deployment** in production environments.  

ğŸ”¹ **Next Steps**:  
- Deploy the container on **cloud platforms** (AWS, GCP, Azure) ğŸŒ  
- Optimize performance using **GPU acceleration** ğŸš€  
- Extend functionality with **REST APIs (FastAPI, Flask)** ğŸ”¦  

---

ğŸ’¡ **Happy Coding!** ğŸ’¡ ğŸš€ğŸ³ğŸ§ 
